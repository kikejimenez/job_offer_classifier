# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_pipeline_classifier.ipynb (unless otherwise specified).

__all__ = ['load_and_split_data', 'tf_input_fn', 'train_input_fs', 'predict_input_fs', 'embedded_text_feature_column_f',
           'load_estimator', 'train', 'f1_score', 'evaluate', 'predict', 'sentiment', 'plot_confusion_matrix',
           'export_estimator', 'Pipeline']

# Cell
import shutil
from os import path,listdir
from tempfile import TemporaryDirectory
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import re
import seaborn as sns
import tensorflow_hub as hub
import tensorflow as tf

# Cell
def load_and_split_data(src_file, frac=0.85,random_state=None):
    df = pd.read_csv(src_file)
    train = df.sample(
        frac=frac, random_state=random_state
    )  #random state is a seed value
    test = df.drop(train.index).sample(random_state=random_state,frac=1.0)
    #examples = test.sample(5)
    return df, {'train': train, 'test': test}#, 'example': examples}

# Cell
def tf_input_fn(df, shuffle=False, **args):
    return tf.compat.v1.estimator.inputs.pandas_input_fn(
        df, df["sentiment"], shuffle=shuffle, **args
    )

def train_input_fs(**args):
    return {
        name: tf_input_fn(df, shuffle=True, num_epochs=None)
        for name, df in args.items()
    }

def predict_input_fs(**args):
    return {
        name: tf_input_fn(df)  for name, df in args.items()
    }

# Cell
def embedded_text_feature_column_f(module_spec="https://tfhub.dev/google/nnlm-en-dim128/1"):
    return hub.text_embedding_column(
        key="payload", module_spec=module_spec
    )

# Cell
def load_estimator(
    embedded_text_feature_column, estimator=tf.estimator.DNNClassifier,model_dir = None
):
    return estimator(
        model_dir = model_dir,
        hidden_units=[500, 100],
        feature_columns=[embedded_text_feature_column],
        n_classes=2,
        optimizer=tf.keras.optimizers.Adagrad(lr=0.003)
    )

# Cell
def train(estimator, train_input_fn,steps=5000):
    result = {}
    for name,input_fn in train_input_fn.items():
        result[name] = estimator.train(input_fn=input_fn, steps=steps)
    return result

# Cell
def f1_score(estimations):
    precision =  estimations['precision']
    recall = estimations['recall']
    return 2 * precision * recall / (precision + recall)

# Cell
def evaluate(estimator, **args:tf_input_fn):
    results = {}
    for name,input_fn in args.items():
        results[name] = estimator.evaluate(input_fn=input_fn)
        results[name]['f1_score'] = f1_score(results[name])
    return results

# Cell
def predict(estimator, df_examples):

    def predict_from_input_fn(estimator, **input_fns):
        res = {}
        for name, input_fn in input_fns.items():
            res[name] = np.array(
                [x["class_ids"][0] for x in estimator.predict(input_fn=input_fn)]
            )
        return res

    return predict_from_input_fn(
        estimator, **predict_input_fs(examples=df_examples)
    )['examples']

# Cell
def sentiment(estimator, doc):
    ex_df = pd.DataFrame([{'payload':doc,'sentiment':0}])
    pred = ["negative", "positive"][predict(estimator,ex_df)[0]]
    return pred #doc + '\n --> \n' + pred

# Cell
def plot_confusion_matrix(df_data, estimator, input_fn, header):
    def get_predictions(estimator, input_fn):
        return [x["class_ids"][0] for x in estimator.predict(input_fn=input_fn)]

    LABELS = ["negative", "positive"]

    # Create a confusion matrix on dataframe data.
    cm = tf.math.confusion_matrix(
        df_data["sentiment"], get_predictions(estimator, input_fn)
    )

    # Normalize the confusion matrix so that each row sums to 1.
    cm = tf.cast(cm, dtype=tf.float32)
    cm = cm / tf.math.reduce_sum(cm, axis=1)[:, np.newaxis]

    sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS)
    plt.title(header)
    plt.xlabel("Predicted")
    plt.ylabel("True")

# Cell
def export_estimator(estimator,dst_estimator):
    shutil.copytree(estimator.model_dir, dst_estimator)

# Cell
class Pipeline:
    '''Class that implements the previous functions as their methods and has a new addtional method `pipeline`.'''
    def __init__(self, src_file, estimator_dir=None, frac=0.85):
        self.frac = 0.8
        self.estimator_dir = estimator_dir
        self.random_state = None
        self.data, self.dfs = load_and_split_data(
            src_file=src_file, random_state=self.random_state, frac=self.frac
        )
        self.train_steps = 5000
        self.module_spec = "https://tfhub.dev/google/nnlm-en-dim128/1"

    def input_fns(self):
        self.input = {}
        self.input['train'] = train_input_fs(train=self.dfs['train'])
        self.input['predict'] = predict_input_fs(**self.dfs)

    def load_estimator(self):
        self.embedded_text_feature_column = embedded_text_feature_column_f(
            module_spec=self.module_spec
        )
        self.estimator = load_estimator(
            self.embedded_text_feature_column, model_dir=self.estimator_dir
        )

    def train(self):
        train(self.estimator, self.input['train'], steps=self.train_steps)

    def evaluate(self):
        self.evaluation = evaluate(self.estimator, **self.input['predict'])

    def plot_confusion_matrix(self, label):
        plot_confusion_matrix(
            self.dfs[label],
            self.estimator,
            self.input['predict'][label],
            header=label + ' data'
        )

    def export_estimator(self, dst_dir):
        try:
            _ = self.estimator
        except:
            self.load_estimator()
        export_estimator(self.estimator, dst_dir)

    def predict(self, df_examples):
        '''Predict from dataframe'''
        return predict(self.estimator,df_examples)

    def sentiment(self, doc):
        return sentiment(self.estimator,doc)

    def pipeline(self):
        ''' The pipeline flow is:
            input_fns --> load_estimator --> train --> evaluate
        '''
        self.input_fns()
        self.load_estimator()
        self.train()
        self.evaluate()